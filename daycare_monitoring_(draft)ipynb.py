# -*- coding: utf-8 -*-
"""DAYCARE MONITORING (Draft)ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y-9bmoSqn-rUp-uMUshD8DsEwLTe-saX
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import cv2
import numpy as np

def preprocess_image(image_path, img_size=(224, 224)):
    image = cv2.imread(image_path)
    if image is None:
        print(f"Warning: Unable to read image {image_path}")
        return None
    image = cv2.resize(image, img_size)
    image = image / 255.0  # Normalize
    return image

def process_images_from_folder(folder_path, img_size=(224, 224)):
    images = []
    # Iterate through all files in the specified folder
    for filename in os.listdir(folder_path):
        full_image_path = os.path.join(folder_path, filename)
        # Check if the file is an image
        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):
            processed_image = preprocess_image(full_image_path, img_size)
            if processed_image is not None:
                images.append(processed_image)
    return np.array(images)

# Define folder paths for training and validation datasets
train_normal_path = "/content/drive/MyDrive/dayacaremonitor/train/normal"  # Replace with actual path
train_abnormal_path = "/content/drive/MyDrive/dayacaremonitor/train/abnormal"  # Replace with actual path
val_normal_path = "/content/drive/MyDrive/dayacaremonitor/validate/normal"  # Replace with actual path
val_abnormal_path = "/content/drive/MyDrive/dayacaremonitor/validate/abnormal"  # Replace with actual path

# Process images
train_normal_images = process_images_from_folder(train_normal_path)
train_abnormal_images = process_images_from_folder(train_abnormal_path)
val_normal_images = process_images_from_folder(val_normal_path)
val_abnormal_images = process_images_from_folder(val_abnormal_path)

print(f"Processed {len(train_normal_images)} normal training images.")
print(f"Processed {len(train_abnormal_images)} abnormal training images.")
print(f"Processed {len(val_normal_images)} normal validation images.")
print(f"Processed {len(val_abnormal_images)} abnormal validation images.")

import cv2
import numpy as np
import os
# Import cv2_imshow from google.colab.patches
from google.colab.patches import cv2_imshow

def preprocess_image(image_path, img_size=(224, 224)):
    image = cv2.imread(image_path)
    if image is None:
        print(f"Warning: Unable to read image {image_path}")
        return None
    image = cv2.resize(image, img_size)
    image = image / 255.0  # Normalize
    return image

def process_images_from_folder(folder_path, img_size=(224, 224)):
    images = []
    image_filenames = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]
    for filename in image_filenames:
        image_path = os.path.join(folder_path, filename)
        processed_image = preprocess_image(image_path, img_size)
        if processed_image is not None:
            images.append(processed_image)
    return np.array(images), image_filenames

def analyze_images(images):
    if len(images) == 0:
        print("No images to analyze.")
        return

    mean_pixel_values = np.mean(images, axis=(0, 1, 2))
    std_pixel_values = np.std(images, axis=(0, 1, 2))

    print("Image Analysis:")
    print(f"Total Images Processed: {len(images)}")
    print(f"Mean Pixel Values (R, G, B): {mean_pixel_values}")
    print(f"Standard Deviation of Pixel Values (R, G, B): {std_pixel_values}")

def show_processed_images(images, filenames):
    for img, filename in zip(images, filenames):
        # Scale the image back to 0-255 range before displaying
        img_to_display = (img * 255).astype(np.uint8)
        cv2_imshow(img_to_display)
        print(f"Processed - {filename}")

# Define folder paths for training and validation datasets
train_normal_path = "/content/drive/MyDrive/dayacaremonitor/train/normal"  # Replace with actual path
train_abnormal_path = "/content/drive/MyDrive/dayacaremonitor/train/abnormal"  # Replace with actual path
val_normal_path = "/content/drive/MyDrive/dayacaremonitor/validate/normal"  # Replace with actual path
val_abnormal_path = "/content/drive/MyDrive/dayacaremonitor/validate/abnormal"  # Replace with actual path

# Process images for training and validation
t_train_normal, f_train_normal = process_images_from_folder(train_normal_path)
t_train_abnormal, f_train_abnormal = process_images_from_folder(train_abnormal_path)
t_val_normal, f_val_normal = process_images_from_folder(val_normal_path)
t_val_abnormal, f_val_abnormal = process_images_from_folder(val_abnormal_path)

# Analyze datasets
analyze_images(t_train_normal)
analyze_images(t_train_abnormal)
analyze_images(t_val_normal)
analyze_images(t_val_abnormal)

# Show some processed images
show_processed_images(t_train_normal, f_train_normal)
show_processed_images(t_train_abnormal, f_train_abnormal)
show_processed_images(t_val_normal, f_val_normal)
show_processed_images(t_val_abnormal, f_val_abnormal)

!pip install ultralytics

import cv2
import numpy as np
import os
from ultralytics import YOLO
# Import cv2_imshow from google.colab.patches
from google.colab.patches import cv2_imshow

def preprocess_image(image_path, img_size=(224, 224)):
    image = cv2.imread(image_path)
    if image is None:
        print(f"Warning: Unable to read image {image_path}")
        return None
    image = cv2.resize(image, img_size)
    image = image / 255.0  # Normalize
    return image

def process_images_from_folder(folder_path, img_size=(224, 224)):
    images = []
    image_filenames = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]
    for filename in image_filenames:
        image_path = os.path.join(folder_path, filename)
        processed_image = preprocess_image(image_path, img_size)
        if processed_image is not None:
            images.append(processed_image)
    return np.array(images), image_filenames

def analyze_images(images):
    if len(images) == 0:
        print("No images to analyze.")
        return

    mean_pixel_values = np.mean(images, axis=(0, 1, 2))
    std_pixel_values = np.std(images, axis=(0, 1, 2))

    print("Image Analysis:")
    print(f"Total Images Processed: {len(images)}")
    print(f"Mean Pixel Values (R, G, B): {mean_pixel_values}")
    print(f"Standard Deviation of Pixel Values (R, G, B): {std_pixel_values}")

def detect_objects_in_image(model, image_path):
    image = cv2.imread(image_path)
    if image is None:
        print(f"Warning: Unable to read image {image_path}")
        return

    results = model(image_path)
    objects = results[0].boxes.xyxy.cpu().numpy()

    for box in objects:
        x1, y1, x2, y2 = map(int, box[:4])
        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)

    cv2_imshow(image)
    print(f"Processed - {image_path}")

def detect_objects_in_folder(folder_path, model):
    image_filenames = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]
    for filename in image_filenames:
        image_path = os.path.join(folder_path, filename)
        detect_objects_in_image(model, image_path)

# Define folder paths for training and validation datasets
train_normal_path = "/content/drive/MyDrive/dayacaremonitor/train/normal"  # Replace with actual path
train_abnormal_path = "/content/drive/MyDrive/dayacaremonitor/train/abnormal"  # Replace with actual path
val_normal_path = ""  # Replace with actual path
val_abnormal_path = "/content/drive/MyDrive/dayacaremonitor/validate/abnormal"  # Replace with actual path

# Load YOLO model
model = YOLO("yolov8n.pt")  # Pre-trained YOLO model

# Detect objects in training and validation datasets
detect_objects_in_folder(train_normal_path, model)
detect_objects_in_folder(train_abnormal_path, model)
detect_objects_in_folder(val_normal_path, model)
detect_objects_in_folder(val_abnormal_path, model)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, TimeDistributed, Reshape
from tensorflow.keras.utils import plot_model
import numpy as np
import os
import cv2

# Define sequence length for LSTM
SEQUENCE_LENGTH = 10

# Define function to load and preprocess dataset
def load_dataset(folder_path, img_size=(64, 64)):
    images = []
    labels = []
    class_labels = {"normal": 0, "abnormal": 1}  # Assign labels

    for class_name, label in class_labels.items():
        class_folder = os.path.join(folder_path, class_name)
        if not os.path.exists(class_folder):
            continue

        for filename in sorted(os.listdir(class_folder)):
            image_path = os.path.join(class_folder, filename)
            image = cv2.imread(image_path)
            if image is None:
                continue
            image = cv2.resize(image, img_size) / 255.0
            images.append(image)
            labels.append(label)

    images = np.array(images)
    labels = np.array(labels)

    # Reshape data into sequences for LSTM
    num_samples = len(images) // SEQUENCE_LENGTH
    images = images[:num_samples * SEQUENCE_LENGTH].reshape(num_samples, SEQUENCE_LENGTH, img_size[0], img_size[1], 3)
    labels = labels[:num_samples * SEQUENCE_LENGTH:SEQUENCE_LENGTH]  # Take one label per sequence

    return np.array(images), np.array(labels)

# Define dataset paths
train_path = "/content/drive/MyDrive/dayacaremonitor/train"
val_path = "/content/drive/MyDrive/dayacaremonitor/validate"

# Load dataset
x_train, y_train = load_dataset(train_path)
x_val, y_val = load_dataset(val_path)

# Convert labels to categorical
y_train = keras.utils.to_categorical(y_train, num_classes=2)
y_val = keras.utils.to_categorical(y_val, num_classes=2)

# Define CNN-LSTM model
model = Sequential([
    TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=(SEQUENCE_LENGTH, 64, 64, 3)),
    TimeDistributed(MaxPooling2D(2, 2)),
    TimeDistributed(Flatten()),
    LSTM(64, return_sequences=False),
    Dense(32, activation='relu'),
    Dense(2, activation='softmax')  # 2 classes: Normal (0), Abnormal (1)
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, epochs=10, batch_size=8, validation_data=(x_val, y_val))

# Save model
model.save("child_safety_model.h5")

# Plot model architecture
plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)